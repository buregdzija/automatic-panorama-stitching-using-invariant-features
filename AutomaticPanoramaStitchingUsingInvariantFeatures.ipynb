{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm: Automatic Panorama Stitching\n",
    "\n",
    "Input: n unordered images\n",
    "\n",
    "I. Extract SIFT features from all n images\n",
    "\n",
    "II. Find k nearest-neighbours for each feature using a k-d tree\n",
    "\n",
    "III. For each image:\n",
    "\n",
    "(i) Select m candidate matching images that have\n",
    "    the most feature matches to this image\n",
    "\n",
    "(ii) Find geometrically consistent feature matches\n",
    "    using RANSAC to solve for the homography between\n",
    "    pairs of images\n",
    "\n",
    "(iii) Verify image matches using a probabilistic model\n",
    "\n",
    "IV. Find connected components of image matches\n",
    "\n",
    "V. For each connected component:\n",
    "\n",
    "(i) Perform bundle adjustment to solve for the rotation\n",
    "    \u00121, \u00122, \u00123 and focal length f of all cameras\n",
    "\n",
    "(ii) Render panorama using multi-band blending\n",
    "Output: Panoramic image(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that extracts SIFT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    descriptors = cv2.xfeatures2d.SIFT_create()\n",
    "    (keypoints, features) = descriptors.detectAndCompute(gray, None)\n",
    "    \n",
    "    keypoints = np.float32([i.pt for i in keypoints])\n",
    "        \n",
    "    return (keypoints, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifies image matches using a probabilistic model\n",
    "\n",
    "Finds connected components of image matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_keypoints(keypoints1, keypoints2, features1, features2, lowe_ratio):\n",
    "    \n",
    "    # first find all possible matches between features\n",
    "    all_matches = all_possible_matches(features1, features2)\n",
    "    # then from all possible matches select valid matched according to the paper(Dawid Lowe concept)\n",
    "    valid_matches = all_valid_matches(all_matches, lowe_ratio)\n",
    "\n",
    "    # According to the paper we chose 4 matches to be enough for matching to take place\n",
    "    if len(valid_matches) > 4:\n",
    "        points1 = np.float32([keypoints1[i] for (_,i) in valid_matches])\n",
    "        points2 = np.float32([keypoints2[i] for (i,_) in valid_matches])\n",
    "        \n",
    "        # We compute transformation matrix needed to transform perspective of first picture\n",
    "        homography = compute_homography(points1, points2)\n",
    "\n",
    "        return homography\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def all_possible_matches(features1, features2):\n",
    "    match_instance = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "    all_matches = match_instance.knnMatch(features1, features2, 2)\n",
    "\n",
    "    return all_matches\n",
    "\n",
    "def all_valid_matches(all_matches, lowe_ratio):\n",
    "    valid_matches = []\n",
    "\n",
    "    for val in all_matches:\n",
    "        if len(val) == 2 and val[0].distance < val[1].distance * lowe_ratio:\n",
    "            valid_matches.append((val[0].trainIdx, val[0].queryIdx))\n",
    "\n",
    "    return valid_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function finds geometrically consistent feature matches using RANSAC to solve for the homography between pairs of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_homography(points1, points2):\n",
    "    (homography, status) = cv2.findHomography(points1, points2, cv2.RANSAC, 0.4)\n",
    "\n",
    "    return homography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Perform bundle adjustment to solve for the rotation \u00121, \u00122, \u00123 and focal length f of all cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_warp_perspective(train_img, query_img, homography):\n",
    "    t_row , t_col = train_img.shape[: 2]\n",
    "    q_row , q_col = query_img.shape[: 2]\n",
    "    \n",
    "    list_pts1 = np.float32([[0 , 0] , [0 , t_row] , [t_col , t_row] , [t_col , 0]]).reshape(-1 , 1 , 2)\n",
    "    temp_points = np.float32([[0 , 0] , [0 , q_row] , [q_col , q_row] , [q_col , 0]]).reshape(-1 , 1 , 2)\n",
    "\n",
    "    list_pts2 = cv2.perspectiveTransform(temp_points , homography)\n",
    "\n",
    "    list_pts = np.concatenate((list_pts1 , list_pts2) , axis = 0)   \n",
    "\n",
    "    [x_min , y_min] = np.int32(list_pts.min(axis = 0).ravel() - 0.5)\n",
    "    [x_max , y_max] = np.int32(list_pts.max(axis = 0).ravel() + 0.5)\n",
    "\n",
    "    translation_dist = [-x_min , -y_min]\n",
    "    #translation_dist = [0, 0]\n",
    "    \n",
    "    #x = train_img.shape[1] + query_img.shape[1]\n",
    "\n",
    "    homography_translation = np.array([[1 , 0 , translation_dist[0]] , [0 , 1 , translation_dist[1]] , [0 , 0 , 1]])\n",
    "    \n",
    "    #warped = cv2.warpPerspective(query_img , homography_translation.dot(homography) , (x, int(train_img.shape[0])))\n",
    "    warped = cv2.warpPerspective(query_img , homography_translation.dot(homography) , (x_max - x_min , y_max - y_min))\n",
    "    warped = alpha_blend(warped, train_img, translation_dist)\n",
    "    \n",
    "    #warped[translation_dist[1] : t_row + translation_dist[1] , translation_dist[0] : translation_dist[0] + t_col ] = train_img\n",
    "    #x = image1.shape[1] + image2.shape[1]\n",
    "    #warped = cv2.warpPerspective(image1, homography, (x , int(image1.shape[0])))\n",
    "    #warped = cv2.perspectiveTransform(image1, homography)\n",
    "    \n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that renders panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch(images):\n",
    "    (image2, image1) = images\n",
    "    \n",
    "    panorama[0:image2.shape[0], 0:image2.shape[1]] = image2\n",
    "    \n",
    "    return panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_blend(img1, img2, translation_dist):\n",
    "    \n",
    "    t_row , t_col = img2.shape[: 2]\n",
    "    # I want to put logo on top-left corner, So I create a ROI\n",
    "    rows, cols, channels = img2.shape\n",
    "    \n",
    "    roi = img1[translation_dist[1] : t_row + translation_dist[1] , translation_dist[0] : translation_dist[0] + t_col]\n",
    "    \n",
    "    # Now create a mask of logo and create its inverse mask also\n",
    "    img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    \n",
    "    # Now black-out the area of logo in ROI\n",
    "    img1_bg = cv2.bitwise_and(roi, roi, mask = mask_inv)\n",
    "    \n",
    "    # Take only region of logo from logo image.\n",
    "    img2_fg = cv2.bitwise_and(img2, img2, mask = mask)\n",
    "    \n",
    "    # Put logo in ROI and modify the main image\n",
    "    dst = cv2.add(img1_bg, img2_fg)\n",
    "    img1[translation_dist[1] : t_row + translation_dist[1] , translation_dist[0] : translation_dist[0] + t_col ] = dst\n",
    "\n",
    "    return img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowe_ratio=0.75\n",
    "\n",
    "images = []\n",
    "\n",
    "images.append(cv2.imread('coala1.png'))\n",
    "images.append(cv2.imread('coala2.png'))\n",
    "\n",
    "# Extract SIFT features from all images\n",
    "keypoints = []\n",
    "features = []\n",
    "for image in images:\n",
    "    (keypoint, feature) = sift_features(image)\n",
    "\n",
    "    keypoints.append(keypoint)\n",
    "    features.append(feature)\n",
    "\n",
    "# Compute all pairwise homographies\n",
    "homographies = {} \n",
    "for i in range(len(images)):\n",
    "    for j in range(i+1, len(images)):\n",
    "        # image that is being warped is image j and we send it first\n",
    "        homography = match_keypoints(keypoints[j], keypoints[i], features[j], features[i], lowe_ratio)\n",
    "        homographies[(i, j)] = homography\n",
    "\n",
    "homography = np.identity(3)\n",
    "ind = True\n",
    "for i in range(len(images)-1):\n",
    "    homography = homographies[(i, i+1)]\n",
    "    #homography = homography @ homographies[(i, i+1)]\n",
    "    if i==0:\n",
    "        #homography = homography @ homographies[(i, i+1)]\n",
    "        panorama = get_warp_perspective(images[i], images[i+1], homography)\n",
    "    else:\n",
    "        (keypoints_p, features_p) = sift_features(panorama)\n",
    "        homography = match_keypoints(keypoints[i+1], keypoints_p, features[i+1], features_p, lowe_ratio)\n",
    "        panorama = get_warp_perspective(panorama, images[i+1], homography)\n",
    "    \n",
    "cv2.imwrite(\"panorama.jpg\", panorama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
